{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install -r requirements.txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gemini as gemini\n",
    "import config as config\n",
    "import bq as bq\n",
    "import gcs as gcs\n",
    "import utils as utils\n",
    "\n",
    "import video_intelligence as gvi\n",
    "from google.cloud import videointelligence_v1 as vi\n",
    "\n",
    "\n",
    "config.WORKING_BUCKET = bucket = \"video-working-bucket-031f\"\n",
    "config.OUTPUT_BUCKET = \"video-working-bucket-031f\"\n",
    "config.INPUT_BUCKET = \"video-input-bucket-031f\"\n",
    "config.PROJECT_ID = \"media-414316\"\n",
    "config.BQ_DATASET = \"video_analytics_031f\"\n",
    "config.BQ_TABLE_GEMINI_RESULT = \"video_analytics_031f.dev_test\"\n",
    "\n",
    "\n",
    "import json\n",
    "import pandas as pd\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video intelligence API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from google.cloud import videointelligence_v1 as vi\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Shot change\n",
    "file = \"fr-FR/SHOT_CHANGE_DETECTION/cdanslair - 1708961447.5183704.json\"\n",
    "\n",
    "data = gcs.read_json_from_gcs(bucket, file)\n",
    "\n",
    "print(data)\n",
    "annotation = vi.AnnotateVideoResponse(data)\n",
    "\n",
    "gvi.splitVideo(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Explicit content\n",
    "file = \"fr-FR/EXPLICIT_CONTENT_DETECTION/test1 - BEST UPCOMING MOVIES 2024 (Trailers) - 1709023409.1792483.json\"\n",
    "data = gcs.read_json_from_gcs(bucket, file)\n",
    "\n",
    "print(data)\n",
    "annotation = vi.AnnotateVideoResponse(data)\n",
    "\n",
    "#gvi.splitVideo(data)\n",
    "gvi.storeVideoIntelligenceData(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEXT DETECTION\n",
    "file = \"fr-FR/TEXT_DETECTION/test1 - BEST UPCOMING MOVIES 2024 (Trailers) - 1709023409.2954755.json\"\n",
    "\n",
    "data = gcs.read_json_from_gcs(bucket, file)\n",
    "annotation = vi.AnnotateVideoResponse(data)\n",
    "\n",
    "#gvi.splitVideo(data)\n",
    "gvi.storeVideoIntelligenceData(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gemini as gemini\n",
    "import config as config\n",
    "import bq as bq\n",
    "import gcs as gcs\n",
    "import utils as utils\n",
    "\n",
    "import video_intelligence as gvi\n",
    "from google.cloud import videointelligence_v1 as vi\n",
    "\n",
    "\n",
    "config.WORKING_BUCKET = bucket = \"video-working-bucket-031f\"\n",
    "config.OUTPUT_BUCKET = \"video-working-bucket-031f\"\n",
    "config.INPUT_BUCKET = \"video-input-bucket-031f\"\n",
    "config.PROJECT_ID = \"media-414316\"\n",
    "config.BQ_DATASET = \"video_analytics_031f\"\n",
    "config.BQ_TABLE_GEMINI_RESULT = \"video_analytics_031f.dev_test2\"\n",
    "\n",
    "\n",
    "import json\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "uri = \"gs://video-output-bucket-031f/CSA/fr-FR/Copy of fr-FR_test1 - BEST UPCOMING MOVIES 2024 (Trailers).mp4/chunks - 1 - 0.0 - 0.633333.mp4\"\n",
    "name = \"CSA/fr-FR/Copy of fr-FR_test1 - BEST UPCOMING MOVIES 2024 (Trailers).mp4/chunks - 1 - 0.0 - 0.633333.mp4\"\n",
    "\n",
    "prompt =    \"\"\"Classification task. Choose between PEGI rating from (3, 7, 12, 16, 18). Based on the following content rate the intensity of the scene from: \n",
    "PEGI 3 The content of video with a PEGI 3 rating is considered suitable for all age groups. The video should not contain any sounds or pictures that are likely to frighten young children. A very mild form of violence (in a comical context or a childlike setting) is acceptable. No bad language should be heard. \n",
    "\n",
    "PEGI 7 video content with scenes or sounds that can possibly frightening to younger children should fall in this category. Very mild forms of violence (implied, non-detailed, or non-realistic violence) are acceptable for a video with a PEGI 7 rating \n",
    "\n",
    "PEGI 12 Video that show violence of a slightly more graphic nature towards fantasy characters or nonrealistic violence towards human-like characters would fall in this age category. Sexual innuendo or sexual posturing can be present, while any bad language in this category must be mild. Gambling as it is normally carried out in real life in casinos or gambling halls can also be present.\n",
    "\n",
    "PEGI 16 This rating is applied once the depiction of violence (or sexual activity) reaches a stage that looks the same as would be expected in real life. The use of bad language in video with a PEGI 16 rating can be more extreme, while video of chance, and the use of tobacco, alcohol or illegal drugs can also be present. \n",
    "\n",
    "PEGI 18 is rating for adult content.\n",
    "\n",
    "CONTENT TO RATE: \n",
    "\"\"\"\n",
    "\n",
    "# prompt =    \"\"\"what do you see ?\n",
    "# VIDEO: \n",
    "# \"\"\"\n",
    "\n",
    "res = gemini.content_moderation_gemini(uri, prompt)\n",
    "print(f\"moderation content done on chunck uri {uri} with res = {res}\")\n",
    "print(80*\"*\")\n",
    "print(res)\n",
    "print(80*\"*\")\n",
    "\n",
    "print(\"save json result in output bucket\")\n",
    "json_file_path = gcs.write_text_to_gcs(config.OUTPUT_BUCKET, utils.replace_extension(name, \".json\"), res, \"text/json\")\n",
    "print(f\"json_file_path = {json_file_path}\")\n",
    "\n",
    "# dict= json.loads(res)\n",
    "# dict= dict[\"csa_rules\"]\n",
    "\n",
    "print(\"read tags from source uri\")\n",
    "bucketname, video_blobname = gcs.split_gcs_uri(uri)\n",
    "tags = gcs.read_tags_from_gcs(bucketname, video_blobname)\n",
    "\n",
    "if tags is None:\n",
    "    print(\"no tags found. WARNING do not save.\")\n",
    "else:\n",
    "    print(f\"uri= {uri} - tags = {tags}\")\n",
    "    dict.update(tags)     \n",
    "    tags[\"description\"]       = res\n",
    "    # generate time\n",
    "    tags[\"update_time\"]       = utils.get_date_time_string()\n",
    "\n",
    "    tags[\"uri\"] = uri\n",
    "    df = pd.DataFrame([tags])\n",
    "\n",
    "    print(df.to_json())\n",
    "    bq.save_bq(df,config.BQ_TABLE_GEMINI_RESULT, project_id=config.PROJECT_ID )\n",
    "\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import base64\n",
    "import vertexai\n",
    "from vertexai.generative_models import GenerativeModel, Part\n",
    "import vertexai.generative_models as generative_models\n",
    "\n",
    "def generate(video_input):\n",
    "    print(f\"content_moderation_gemini {video_input}\")\n",
    "    if type(video_input) == str:\n",
    "        video_input = Part.from_uri(uri=video_input, mime_type=\"video/mp4\")\n",
    "\n",
    "    elif type(input) == 'Part':\n",
    "        video_input = video_input\n",
    "    else:\n",
    "        print(f\"input is not supported: {video_input}\")\n",
    "        return \n",
    "    vertexai.init(project=\"media-414316\", location=\"europe-west1\")\n",
    "    model = GenerativeModel(\"gemini-1.0-pro-vision-001\")\n",
    "    responses = model.generate_content(\n",
    "        [\"\"\"You are an expert in violence content moderation.\n",
    "    Explain why you provide the rating with the content moderation rule and without offensive quote.\n",
    "\n",
    "    You classify text with CSA rules. Answer short JSON results like an API without quote with the following format:\n",
    "    {\\\"\\\\\\\"csa_rules\\\\\\\": {\n",
    "        \\\\\\\"violence\\\\\\\": \\\"0\\\",\n",
    "        \\\\\\\"violence_evidence\\\\\\\":  \\\\\\\"\\\\\\\"\n",
    "    }\n",
    "\n",
    "    Evaluate CSA rules based on this video part and output them in JSON. Return a valide JSON format.\"\"\", video_input, \"\"\"JSON\"\"\"],\n",
    "        generation_config={\n",
    "            \"max_output_tokens\": 2048,\n",
    "            \"temperature\": 0,\n",
    "            \"top_p\": 1,\n",
    "            \"top_k\": 40\n",
    "        },\n",
    "        safety_settings={\n",
    "            generative_models.HarmCategory.HARM_CATEGORY_HATE_SPEECH: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
    "            generative_models.HarmCategory.HARM_CATEGORY_DANGEROUS_CONTENT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
    "            generative_models.HarmCategory.HARM_CATEGORY_SEXUALLY_EXPLICIT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
    "            generative_models.HarmCategory.HARM_CATEGORY_HARASSMENT: generative_models.HarmBlockThreshold.BLOCK_MEDIUM_AND_ABOVE,\n",
    "        },\n",
    "        stream=True,\n",
    "    )\n",
    "  \n",
    "        \n",
    "\n",
    "\n",
    "    answer = []\n",
    "    for response in responses:\n",
    "        text = response.text\n",
    "        print(text, end=\"\")    \n",
    "        answer.append(text)\n",
    "\n",
    "    str_json = \"\".join(answer)\n",
    "    #str_json = CleanJsonOutput(str_json)\n",
    "    #print(str_json)\n",
    "\n",
    "    return str_json\n",
    "  \n",
    "video_input = \"gs://video-output-bucket-031f/CSA/fr-FR/Copy of fr-FR_test1 - BEST UPCOMING MOVIES 2024 (Trailers).mp4/chunks - 1 - 0.0 - 0.633333.mp4\"\n",
    "\n",
    "#video1 = Part.from_uri(uri=video_input, mime_type=\"video/mp4\")\n",
    "generate(video_input)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%pip install jsonpath-ng"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import json\n",
    "from google.cloud import bigquery  # You'll need to install this library\n",
    "\n",
    "# Construct a BigQuery client\n",
    "client = bigquery.Client()\n",
    "\n",
    "# Replace with your BigQuery project ID and query\n",
    "project_id = 'media-414316'\n",
    "query = \"\"\" \n",
    "SELECT * FROM video_analytics_031f.results\n",
    "\"\"\"\n",
    "\n",
    "# Retrieve results from BigQuery\n",
    "query_job = client.query(query)\n",
    "results = query_job.result()\n",
    "\n",
    "# Placeholder mapping (customize this according to your needs)\n",
    "field_mapping = {\n",
    "    \"uri\": \"video_source\",  # Example, assuming 'video_source' has the URI\n",
    "    \"time_start\": \"start_time_offset\",\n",
    "    \"time_stop\": \"end_time_offset\"\n",
    "}\n",
    "\n",
    "# Placeholder for generating time offsets (you'll need to implement the logic)\n",
    "def generate_time_offsets(start_time, end_time):\n",
    "    # Your logic to convert start_time and end_time into the required format\n",
    "    # Example:\n",
    "    if start_time:\n",
    "        start_seconds = start_time.seconds  # Assuming timestamp object\n",
    "        start_nanos = start_time.microseconds * 1000\n",
    "    else:\n",
    "        start_seconds, start_nanos = 0, 0  # Or default values\n",
    "\n",
    "    if end_time:\n",
    "        end_time = end_time.seconds  # Assuming timestamp object\n",
    "        end_nanos = end_time.microseconds * 1000\n",
    "    else:\n",
    "        end_time, end_nanos = 0, 0  # Or default values\n",
    "\n",
    "    return {\"seconds\": start_seconds, \"nanos\": start_nanos}, \\\n",
    "           {\"seconds\": end_time, \"nanos\": end_nanos}\n",
    "\n",
    "#  Structure for the output JSON\n",
    "output_json = {\n",
    "    \"annotation_results\": []\n",
    "}\n",
    "\n",
    "# Iterate through BigQuery results\n",
    "for row in results:\n",
    "    annotation_result = {}\n",
    "\n",
    "    # Populate 'input_uri' \n",
    "    annotation_result[\"input_uri\"] = row.get(field_mapping.get(\"uri\", \"\")) \n",
    "\n",
    "    # Populate segment\n",
    "    segment = {}\n",
    "    start_offset, end_offset = generate_time_offsets(\n",
    "        row.get(field_mapping.get(\"time_start\")),\n",
    "        row.get(field_mapping.get(\"time_stop\")) \n",
    "    )\n",
    "    segment[\"start_time_offset\"] = start_offset\n",
    "    segment[\"end_time_offset\"] = end_offset\n",
    "    annotation_result[\"segment\"] = segment\n",
    "\n",
    "    # ... (Add logic for populating other fields)\n",
    "\n",
    "    output_json[\"annotation_results\"].append(annotation_result)\n",
    "\n",
    "# Convert to JSON string\n",
    "json_output = json.dumps(output_json, indent=2)\n",
    "print(json_output)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TEST 2\n",
    "\n",
    "\n",
    "import json\n",
    "from google.cloud import bigquery\n",
    "\n",
    "# Replace with your project ID and BigQuery dataset/table names\n",
    "PROJECT_ID = \"media-414316\"\n",
    "DATASET = \"video_analytics_031f\"\n",
    "TABLE = \"results\"\n",
    "\n",
    "\n",
    "def bigquery_to_json(bigquery_results, video_source):\n",
    "    annotation_results = []\n",
    "    #shot_label_annotations = []\n",
    "\n",
    "    last_end_time_offset = {\n",
    "        \"seconds\": 0,\n",
    "        \"nanos\": 0\n",
    "    }\n",
    "    segments = []\n",
    "    \n",
    "    result_item = {\n",
    "        \"input_uri\": video_source,  \n",
    "        \"segment\": {\n",
    "            \"start_time_offset\": {\n",
    "                \"seconds\": 0,\n",
    "                \"nanos\": 0\n",
    "                },\n",
    "            \"end_time_offset\": last_end_time_offset\n",
    "        },\n",
    "        # \"segment_label_annotations\": [],\n",
    "        \"shot_label_annotations\": []\n",
    "    }\n",
    "    annotation_results.append(result_item)\n",
    "\n",
    "    for row in bigquery_results:\n",
    "        description = get_description(row)\n",
    "        if description: # and description:\n",
    "\n",
    "            # Function to calculate time offsets based on your data\n",
    "            start_time_offset, end_time_offset = calculate_time_offsets(row)\n",
    "\n",
    "            segment_label = {\n",
    "                \"entity\": {\n",
    "                    \"entity_id\": \"/m/00000\",\n",
    "\n",
    "                    # \"language_code\": \"en-US\"\n",
    "                    \"description\": description\n",
    "                },\n",
    "                \"segments\": [{\n",
    "                    \"segment\": {\n",
    "                        \"start_time_offset\": start_time_offset,\n",
    "                        \"end_time_offset\": end_time_offset\n",
    "                    },\n",
    "                    # Add 'confidence' if applicable\n",
    "                    'confidence': 1.0\n",
    "                }]\n",
    "            }\n",
    "            last_end_time_offset = end_time_offset\n",
    "            \n",
    "            segments.append(segment_label)\n",
    "            \n",
    "            result_item[\"shot_label_annotations\"].append(segment_label)\n",
    "            #shot_label_annotations.append(segment_label)\n",
    "\n",
    "        #if len(result_item) > 0 and len(result_item[\"shot_label_annotations\"]) > 0:\n",
    "        annotation_results.append(result_item)\n",
    "\n",
    "    #if len(annotation_results) > 0:\n",
    "    annotation_results[0]['segment']['end_time_offset'] = last_end_time_offset\n",
    "    \n",
    "\n",
    "    return {\"annotation_results\": annotation_results}\n",
    "\n",
    "# Example of how to calculate offsets (adjust to your data)\n",
    "\n",
    "\n",
    "def calculate_time_offsets(row):\n",
    "    start = float(row.get(\"time_start\", \"0\"))  # Adjust field name if needed\n",
    "    start_seconds, start_nanos = getSecondsNanos(start)\n",
    "\n",
    "    end = float(row.get(\"time_stop\", \"0\"))    # Adjust field name if needed\n",
    "    end_seconds, end_nanos = getSecondsNanos(end)\n",
    "\n",
    "    return {\"seconds\": start_seconds, \"nanos\": start_nanos}, {\"seconds\": end_seconds, \"nanos\": end_nanos}\n",
    "\n",
    "\n",
    "def getSecondsNanos(start):\n",
    "    start_seconds = int(start)\n",
    "    start_nanos = int((start - start_seconds) * 10000000)\n",
    "    return start_seconds, start_nanos\n",
    "\n",
    "\n",
    "def get_description(row):\n",
    "    description = row.get(f\"description\", \"\")\n",
    "    index = row.get(\"index\", \"0\")\n",
    "    start = float(row.get(\"time_start\", \"0\"))  # Adjust field name if needed\n",
    "    end = float(row.get(\"time_stop\", \"0\"))    # Adjust field name if needed\n",
    "\n",
    "    if len(description) > 0:\n",
    "        description = f\"{index} ({start} - {end}) : {description}\"\n",
    "        print(description)\n",
    "        return description\n",
    "    else:\n",
    "        return None\n",
    "\n",
    "\n",
    "# BigQuery query execution\n",
    "client = bigquery.Client(project=PROJECT_ID)\n",
    "#filter = \"gs://video-input-bucket-031f/fr-FR/House of the Dragon - Rhaenyra and Criston Cole sex scene.mp4\"\n",
    "filter = \"gs://video-input-bucket-031f/fr-FR/BEST UPCOMING MOVIES  2024 (Trailers).mp4\"\n",
    "\n",
    "query = f\"SELECT * FROM `{DATASET}.{TABLE}` where video_source = '{filter}'  order by  CAST(index AS INT64)  asc\"\n",
    "print(query)\n",
    "query_job = client.query(query)\n",
    "results = query_job.result()\n",
    "\n",
    "# Conversion and output\n",
    "json_data = bigquery_to_json(results, filter)\n",
    "label_moderation = json.dumps(json_data, indent=2)\n",
    "print(label_moderation)\n",
    "\n",
    "# write file with content label_moderation\n",
    "\n",
    "with open('label_moderation_Trailers.json', 'w') as f:\n",
    "    f.write(label_moderation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
